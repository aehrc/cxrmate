{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/projects/pawsey0864/anicolson/environments/multimodal_23/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "/software/projects/pawsey0864/anicolson/environments/multimodal_23/lib/python3.10/site-packages/transformers/models/convnext/feature_extraction_convnext.py:28: FutureWarning: The class ConvNextFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ConvNextImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os, requests, torch, transformers, warnings\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from io import BytesIO\n",
    "\n",
    "\n",
    "ckpt_name = 'aehrc/mimic-cxr-report-gen-single'\n",
    "\n",
    "cache_dir = '/scratch/pawsey0864/anicolson/checkpoints'\n",
    "\n",
    "os.environ['TRANSFORMERS_CACHE'] = cache_dir\n",
    "os.environ['HUGGINGFACE_HUB_CACHE'] = cache_dir\n",
    "\n",
    "encoder_decoder = transformers.AutoModel.from_pretrained(ckpt_name, trust_remote_code=True, cache_dir=cache_dir)\n",
    "tokenizer = transformers.PreTrainedTokenizerFast.from_pretrained(ckpt_name, cache_dir=cache_dir)\n",
    "image_processor = transformers.AutoFeatureExtractor.from_pretrained(ckpt_name, cache_dir=cache_dir)\n",
    "\n",
    "test_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(size=image_processor.size['shortest_edge']),\n",
    "        transforms.CenterCrop(size=[\n",
    "            image_processor.size['shortest_edge'],\n",
    "            image_processor.size['shortest_edge'],\n",
    "        ]\n",
    "        ),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=image_processor.image_mean,\n",
    "            std=image_processor.image_std,\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 384, 384])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.stritch.luc.edu/lumen/meded/radio/curriculum/IPM/PCM/86a_labelled.jpg'\n",
    "response = requests.get(url)\n",
    "image_a = Image.open(BytesIO(response.content))\n",
    "image_a = image_a.convert('RGB')\n",
    "\n",
    "url = 'https://prod-images-static.radiopaedia.org/images/566180/d527ff6fc1482161c9225345c4ab42_big_gallery.jpg'\n",
    "response = requests.get(url)\n",
    "image_b = Image.open(BytesIO(response.content))\n",
    "image_b = image_b.convert('RGB')\n",
    "\n",
    "image_a = test_transforms(image_a)\n",
    "image_b = test_transforms(image_b)\n",
    "\n",
    "images = torch.stack([image_a, image_b], dim=0)\n",
    "images.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = encoder_decoder.generate(\n",
    "    pixel_values=images,\n",
    "    special_token_ids=[tokenizer.sep_token_id],\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    return_dict_in_generate=True,\n",
    "    use_cache=True,\n",
    "    max_length=256,\n",
    "    num_beams=4,\n",
    ")\n",
    "\n",
    "findings, impression = encoder_decoder.split_and_decode_sections(\n",
    "    outputs.sequences,\n",
    "    [tokenizer.sep_token_id, tokenizer.eos_token_id],\n",
    "    tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Findings: There is a moderate to large left pleural effusion with adjacent atelectasis. The right lung is clear. No pneumothorax identified. The size and appearance of the cardiomediastinal silhouette is unchanged.\n",
      "Impression: Moderate to large left pleural effusion with adjacent atelectasis.\n",
      "\n",
      "Findings: The patient has had prior median sternotomy with aortic valve replacement. Sternotomy wires are intact and aligned. Sequential radiographs show advancement of a feeding tube initially positioned in the mid esophagus, through the gastroesophageal junction, and into the stomach. Moderate cardiomegaly despite the projection is unchanged. Mediastinal contours are stable. There is no pneumothorax. Mild pulmonary edema is unchanged.\n",
      "Impression: Feeding tube terminates in stomach. Stable mild pulmonary edema. Stable moderate cardiomegaly.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, j in zip(findings, impression):\n",
    "    print(f'Findings: {i}\\nImpression: {j}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_decoder.device"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cxrmate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
